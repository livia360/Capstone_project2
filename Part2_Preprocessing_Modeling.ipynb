{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d725f4bb",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries-and-load-the-data\" data-toc-modified-id=\"Import-libraries-and-load-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import libraries and load the data</a></span></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Target-variable\" data-toc-modified-id=\"Target-variable-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Target variable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Log-Transformation\" data-toc-modified-id=\"Log-Transformation-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Log Transformation</a></span></li></ul></li><li><span><a href=\"#Encoding-categorical-features\" data-toc-modified-id=\"Encoding-categorical-features-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Encoding categorical features</a></span></li><li><span><a href=\"#Train/-Test-Splits\" data-toc-modified-id=\"Train/-Test-Splits-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Train/ Test Splits</a></span></li><li><span><a href=\"#1.2-Scaler\" data-toc-modified-id=\"1.2-Scaler-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>1.2 Scaler</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dummy-Regressor\" data-toc-modified-id=\"Dummy-Regressor-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Dummy Regressor</a></span></li><li><span><a href=\"#R^2---Goodness-of-Fit\" data-toc-modified-id=\"R^2---Goodness-of-Fit-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>R^2 - Goodness of Fit</a></span></li><li><span><a href=\"#Multiple-Linear-Regression\" data-toc-modified-id=\"Multiple-Linear-Regression-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Multiple Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Interpreting-coefficients\" data-toc-modified-id=\"Interpreting-coefficients-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Interpreting coefficients</a></span></li></ul></li><li><span><a href=\"#Ordinary-Least-Squares-(OLS)\" data-toc-modified-id=\"Ordinary-Least-Squares-(OLS)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Ordinary Least Squares (OLS)</a></span></li><li><span><a href=\"#Lasso-L1-Norm-Regression\" data-toc-modified-id=\"Lasso-L1-Norm-Regression-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Lasso L1 Norm Regression</a></span></li><li><span><a href=\"#Ridge-L2-norm-regression\" data-toc-modified-id=\"Ridge-L2-norm-regression-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Ridge L2 norm regression</a></span></li><li><span><a href=\"#Random-Forest-Regressor\" data-toc-modified-id=\"Random-Forest-Regressor-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Random Forest Regressor</a></span></li></ul></li><li><span><a href=\"#Summary-and-further-analysis\" data-toc-modified-id=\"Summary-and-further-analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Summary and further analysis</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ab223",
   "metadata": {},
   "source": [
    "In this project, I will train and test regression models on superstore's sales data and then evaluate the performance and predictive power of models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3616f",
   "metadata": {},
   "source": [
    "## Import libraries and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85bc6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, cross_val_score, ShuffleSplit\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, LassoLarsCV, LassoLarsIC, Ridge, RidgeCV, ElasticNet, ElasticNetCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import statsmodels.api as sm \n",
    "\n",
    "from scipy.stats import norm, probplot\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from library.sb_utils import save_file\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid') \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0f8cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShipMode</th>\n",
       "      <th>Segment</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Months</th>\n",
       "      <th>Year</th>\n",
       "      <th>zip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Second Class</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>14.620</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8714</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Class</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>22.368</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5164</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Class</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Furnishings</td>\n",
       "      <td>48.860</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.1694</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ShipMode    Segment             City       State Region  \\\n",
       "0    Second Class  Corporate      Los Angeles  California   West   \n",
       "1  Standard Class   Consumer  Fort Lauderdale     Florida  South   \n",
       "2  Standard Class   Consumer      Los Angeles  California   West   \n",
       "\n",
       "          Category Sub-Category   Sales  Quantity  Discount   Profit  Months  \\\n",
       "0  Office Supplies       Labels  14.620         2       0.0   6.8714       6   \n",
       "1  Office Supplies      Storage  22.368         2       0.2   2.5164      10   \n",
       "2        Furniture  Furnishings  48.860         7       0.0  14.1694       6   \n",
       "\n",
       "   Year  zip_rank  \n",
       "0  2016       278  \n",
       "1  2015       318  \n",
       "2  2014       277  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/clean_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56cb2148",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4948 entries, 0 to 4947\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ShipMode      4948 non-null   object \n",
      " 1   Segment       4948 non-null   object \n",
      " 2   City          4948 non-null   object \n",
      " 3   State         4948 non-null   object \n",
      " 4   Region        4948 non-null   object \n",
      " 5   Category      4948 non-null   object \n",
      " 6   Sub-Category  4948 non-null   object \n",
      " 7   Sales         4948 non-null   float64\n",
      " 8   Quantity      4948 non-null   int64  \n",
      " 9   Discount      4948 non-null   float64\n",
      " 10  Profit        4948 non-null   float64\n",
      " 11  Months        4948 non-null   int64  \n",
      " 12  Year          4948 non-null   int64  \n",
      " 13  zip_rank      4948 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 541.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3158d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61843913",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bbbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df.select_dtypes(include=['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb0ee92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Months</th>\n",
       "      <th>Year</th>\n",
       "      <th>zip_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.620</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8714</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.368</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5164</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.860</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.1694</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.280</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9656</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.504</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.7825</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sales  Quantity  Discount   Profit  Months  Year  zip_rank\n",
       "0  14.620         2       0.0   6.8714       6  2016       278\n",
       "1  22.368         2       0.2   2.5164      10  2015       318\n",
       "2  48.860         7       0.0  14.1694       6  2014       277\n",
       "3   7.280         4       0.0   1.9656       6  2014       277\n",
       "4  18.504         3       0.2   5.7825       6  2014       277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c1783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.pairplot() output a figure containing histogram and scatter plot between each variable\n",
    "# sns.set_palette('Set2')\n",
    "# sns.pairplot(data=df, height=3);\n",
    "df.hist(figsize=(15,10), bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae1abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['log_sales'] = np.log(df['Sales'])\n",
    "df.hist(figsize=(15,10), bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34028e",
   "metadata": {},
   "source": [
    "### Target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of sales of all states and normal probability plot\n",
    "\n",
    "sns.distplot(df['Sales'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = probplot(df['Sales'], plot=plt)\n",
    "plt.savefig('images/target.png')\n",
    "\n",
    "print(\"Skewness: %f\" % df['Sales'].skew())\n",
    "print(\"Kurtosis: %f\" % df['Sales'].kurt())\n",
    "\n",
    "# 'Sales' is skewed to the right due to West Virginia, Vermont, District of Columbia and a few others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8223e8c",
   "metadata": {},
   "source": [
    "#### Log Transformation\n",
    "\n",
    "Log transformations are often recommended for skewed data, such as monetary measures. Log transforming data has the effect of spreading out clumps of data and bringing together spread-out data.\n",
    "\n",
    "After a log transformation of 'Sales', the histogram is more or less symmetric. I’ve moved the bigger states sales closer together and spaced out the smaller states sales.\n",
    "\n",
    "One reason is to make data more “normal”, or symmetric because it could help meet the assumption of constant variance in the context of linear modeling. Yet another reason is to help make a non-linear relationship more linear. But while it’s easy to implement a log transformation, it can complicate interpretation. Let’s say we fit a linear model with a log-transformed dependent variable - 'Sales'. How do we interpret the coefficients?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76fc84",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#histogram and normal probability plot\n",
    "sns.distplot(df['sales_log'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = probplot(df['sales_log'], plot=plt)\n",
    "\n",
    "print(\"Skewness: %f\" % df['sales_log'].skew())\n",
    "print(\"Kurtosis: %f\" % df['sales_log'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f23bc",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Months'] = df.Months.astype('category')\n",
    "#df['Category'] = df.Category.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical to Quantitative relationship\n",
    "categorical_features = [i for i in df.columns if (df.dtypes[i] == \"object\") or (df.dtypes[i] == \"category\")]\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling encoding the categorical features\n",
    "# categorical_features = ['Segment', 'Category', 'Sub-Category', 'Months']\n",
    "for cat in categorical_features:\n",
    "    label = LabelEncoder()\n",
    "    df[cat] = label.fit_transform(df[cat])\n",
    "\n",
    "df[cat].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad914892",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d09f3",
   "metadata": {},
   "source": [
    "q1 = df['Category'].quantile(0.25)\n",
    "q3 = df['Category'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "\n",
    "filter = (df['Category'] >= q1 -1.5 *IQR) & (df['Category'] <= q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ac584",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df['Sub-Category'].quantile(0.25)\n",
    "q3 = df['Sub-Category'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "\n",
    "filter = (df['Sub-Category'] >= q1 -1.2 *IQR) & (df['Sub-Category'] <= q3 + 1.2 *IQR)\n",
    "df = df.loc[filter]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda77be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(['Months', 'Region', 'City', 'log_sales'], axis=1).corr()\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(corr, annot=True,cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = corr.abs().unstack().drop_duplicates().reset_index()\n",
    "c = c.rename(columns={'level_0': 'feature 1', 'level_1': 'feature 2', 0: 'Correlation'})\n",
    "c = c.query('.2 <= Correlation < 1').sort_values(by = 'Correlation', ascending = False).reset_index(drop=True)\n",
    "c.style.background_gradient(cmap='Set1_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27bfe5d",
   "metadata": {},
   "source": [
    "Based on the cross correlation coefficients, I would expect the following:\n",
    "\n",
    "- **'Quantity'** has a positive correlation with the sales.\n",
    "\n",
    "- **'Postal code'**: In the densely **populated states or postal codes** in the west and east regions, the sales is high. As most of sales came from the category of 'Technology', this fact could be interpreted as more university students and more tech related residents in that region. The attractive higher education system and companies lead to a fact for high demand of the tech-related products. Hence, the sales would increase.\n",
    "\n",
    "- **'Discount'** has a strong negative correlation with 'Sales' and also with 'zip_rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[~(df['Discount'] ==0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb06741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "quantity_sales = df.groupby('Quantity')['Sales'].mean()\n",
    "\n",
    "plt.scatter(quantity_sales.index, quantity_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Quanity')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();\n",
    "# on average per quantity looks linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity2'] = df['Quantity'] **3\n",
    "quantity_sales = df.groupby('Quantity2')['Sales'].mean()\n",
    "\n",
    "plt.scatter(quantity_sales.index, quantity_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Quanity')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sales = df.groupby('Sub-Category')['Sales'].mean()\n",
    "q1 = df['Sub-Category'].quantile(0.25)\n",
    "q3 = df['Sub-Category'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "\n",
    "filter = (df['Sub-Category'] >= q1 -1 *IQR) & (df['Sub-Category'] <= q3 + 1.2 *IQR)\n",
    "df = df.loc[filter]\n",
    "\n",
    "plt.scatter(cat_sales.index, cat_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Zip_rank')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f11128",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Category2'] = df['Category'] **2\n",
    "cat_sales = df.groupby('Category2')['Sales'].mean()\n",
    "\n",
    "plt.scatter(cat_sales.index, cat_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Zip_rank')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15397007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sub-Category2'] = df['Sub-Category'] **2\n",
    "cat_sales = df.groupby('Sub-Category2')['Sales'].mean()\n",
    "\n",
    "plt.scatter(cat_sales.index, cat_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Zip_rank')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e512c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df['zip_rank'].quantile(0.25)\n",
    "q3 = df['zip_rank'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "\n",
    "filter = (df['zip_rank'] >= q1 -1.5 *IQR) & (df['zip_rank'] <= q3 + 1.2 *IQR)\n",
    "df = df.loc[filter]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ceec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_sales = df.groupby('zip_rank')['Sales'].mean()\n",
    "\n",
    "plt.scatter(zip_sales.index, zip_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Zip_rank')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83140e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zip_rank2'] = df['zip_rank'] **2\n",
    "zip_sales = df.groupby('zip_rank2')['Sales'].mean()\n",
    "\n",
    "plt.scatter(zip_sales.index, zip_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Zip_rank')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_sales = df.groupby('Discount')['Sales'].mean()\n",
    "\n",
    "q1 = df['Discount'].quantile(0.25)\n",
    "q3 = df['Discount'].quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "\n",
    "filter = (df['Discount'] >= q1 -1.5 *IQR) & (df['Discount'] <= q3 + 1.5 *IQR)\n",
    "df = df.loc[filter]\n",
    "\n",
    "plt.scatter(discount_sales.index, discount_sales)\n",
    "plt.title(\"Linearity check\")\n",
    "plt.xlabel('Discount')\n",
    "plt.ylabel('Sales')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d4293",
   "metadata": {},
   "source": [
    "### Train/ Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575cad8b",
   "metadata": {},
   "source": [
    "In order to fit the models on the data, I first define the ‘X’ variable (independent variable) and the ‘Y’ variable (dependent variable). After defining the variables, split the data into a train set and test set using the ‘train_test_split’ function by scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = sales \n",
    "# 𝑋  = all the other features (or independent variables, predictors or explanatory variables) \n",
    "# use to fit a linear regression model and predict\n",
    "# X = df.drop(['sales_log', 'Sales', 'Year', 'Profit', 'Region', 'City'], axis=1)\n",
    "X = df.drop(['log_sales', 'Sales', 'Segment', 'State', 'Months', 'Region', 'City', 'Year'], axis=1)\n",
    "y = df['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd63d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training set: is a subset of the dataset used to build and fit predictive models\n",
    "# test set used for evaluation purposes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76855bb8",
   "metadata": {},
   "source": [
    "### 1.2 Scaler\n",
    "\n",
    "Data standardization is useful when you want to compare data that correspond to different units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de128f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call StandardScaler method on `X_tr` to fit the scaler;\n",
    "# use `transform()` method to apply the scaling to both the train and test split.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2250222",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4622e02",
   "metadata": {},
   "source": [
    "To build and train five different types of linear regression models:\n",
    "    - OLS model\n",
    "    - Lasso regression model\n",
    "    - Ridge regression model\n",
    "    - Elastic Net regression model\n",
    "    - Random forest regression model\n",
    "    \n",
    "    The linear regression model assumes a linear relationship between the input and output variables. If this relationship is present, we use Pearson correlation coefficients to measure the direction and strength of the linear relationship between target variable and predictor variables, and use evaluation metrics such as R^2 and mean square error to measure the predictive power of the linear regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0688d9",
   "metadata": {},
   "source": [
    "### Dummy Regressor\n",
    "\n",
    "The most basic understanding of the dependent variable 'sales' is a measure of central tendency. Calculate the mean of 'Sales' is considered as a baseline model because there is no assumptions about the distribution of the data or its dependencies on any other data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain a baseline idea that the average sales  of the data is $35.5\n",
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the skilearn dummy regressor on the training data\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "print(dumb_reg.constant_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2898b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = train_mean * np.ones(len(y_test))\n",
    "r2_score(y_test, y_pred)\n",
    "\n",
    "#### Well that is bad  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8546a95",
   "metadata": {},
   "source": [
    "### R^2 - Goodness of Fit\n",
    "\n",
    "- R^2 is a common metric, and interpretable in terms of the amount of variance explained. 𝑅^2  tells us how much of the variance we're explaining beyond that of using the mean.\n",
    "- Other metrics that summarize the difference between predicted and actual values are _mean absolute error_ and _mean squared error_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0692944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare dictionary to store results\n",
    "models = {}\n",
    "models['Models'] = []\n",
    "models['r2'] = []\n",
    "models['mae'] = []\n",
    "models['rmse'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5353f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model, x_train, x_test, y_train, y_test, title):\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    cv_5 = cross_val_score(model, x_train, y_train, cv=5)\n",
    "    r2 = round(cv_5.mean()*100,2)\n",
    "    \n",
    "    y_test_pred = model.predict(x_test)\n",
    "    residuals = y_test - y_test_pred\n",
    "        \n",
    "    # Calculate our errors\n",
    "    mae = round(mean_absolute_error(y_test, y_test_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, y_test_pred)), 2)\n",
    "\n",
    "    # append our results to our lists\n",
    "    models['Models'].append(title)\n",
    "    models['r2'].append(r2)\n",
    "    models['mae'].append(mae)\n",
    "    models['rmse'].append(rmse)\n",
    "\n",
    "    print(\"R2: \", r2, \"\\nMAE: \", mae, \"\\nRMSE: \", rmse, \"\\n{} predictors used for this model\".format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7432c64",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "Linear Regression is one of mostly used machine learning algorithms to predict values within a continuous range.\n",
    "Examples of how businesses use Linear Regression machine learning models are the following:\n",
    "\n",
    "-       Predicting Sales, and any other numeric continues values (such as Prices, Revenue ...)\n",
    "-       Understanding the relations between variables and which variables affect Sales (y) the most and measuring by how much?\n",
    "-       Understanding trends - positive or negative ? and measuring by how much using model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaae0be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_model(mlr, X_train, X_test, y_train, y_test, 'Linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b55790",
   "metadata": {},
   "source": [
    "The linear regression model explains only about 27% of the variation from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the slope and intercept of the line best fit.\n",
    "print(mlr.intercept_)\n",
    "print(mlr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed832aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefficients = abs(mlr.coef_).transpose()\n",
    "features = X.columns\n",
    "\n",
    "feature_importance = {}\n",
    "for i, coef in enumerate(coefficients):\n",
    "    feature_importance[features[i]] = coef\n",
    "    \n",
    "feature_importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', columns=['feature_importance'])\n",
    "feature_importance_df.sort_values('feature_importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55f96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the coefficients\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(mlr.coef_)), mlr.coef_)\n",
    "plt.xticks(range(len(mlr.coef_)), features, rotation=60)\n",
    "plt.margins(0.02)\n",
    "plt.savefig('images/features.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e93947",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ae435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, marker='.', linestyle='None')\n",
    "sns.regplot(data=df, x=y_test, y=y_pred, scatter=False, color='red')\n",
    "\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Linear regression model Predicted vs Actual Values', fontdict={'fontsize': 14})\n",
    "plt.savefig('images/lr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339fb45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top important features \n",
    "importances = mlr.coef_\n",
    "\n",
    "indices = np.argsort(importances)[-10:] \n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='g', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60c5e8",
   "metadata": {},
   "source": [
    "** Top Predictors:**\n",
    "    - Sub_Category\n",
    "    - Profit\n",
    "    - Category\n",
    "    - Discount\n",
    "    - Quantity\n",
    "    - Postal code   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6d66c",
   "metadata": {},
   "source": [
    "#### Interpreting coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f145c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to interpret the 1 unit change of x on y?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f8425",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit', \n",
    "X = df.drop(['log_sales', 'Sales', 'Segment', 'State', 'Months', 'Region', 'City', 'Year'], axis=1)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "y = df['Sales']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "features = X_train.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5091b3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the third model, it is the same algorithm, just different inputs\n",
    "olsmod = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Evaluate the model\n",
    "print(olsmod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf387f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F-statistic:', olsmod.fvalue)\n",
    "print('Probability of observing value at least as high as F-statistic:', olsmod.f_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbe952",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = olsmod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b41ace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, marker='.', linestyle='None')\n",
    "sns.regplot(data=df, x=y_test, y=y_pred, scatter=False, color='red')\n",
    "\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Ordinary Least Squares (OLS) model Predicted vs Actual Values', fontdict={'fontsize': 14});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaefcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df.Sales - np.exp(olsmod.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals, marker='.')\n",
    "plt.axhline(y=0, linestyle='--', color='red');\n",
    "plt.savefig('images/residuals.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_RMSE(test, test_pred):    \n",
    "    return np.sqrt(mean_squared_error(test, test_pred))\n",
    "\n",
    "print(check_RMSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "olsmod = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Evaluate the model\n",
    "print(olsmod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a8a90",
   "metadata": {},
   "source": [
    "### Lasso L1 Norm Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d165e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X_train, y_train)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "print(\"AIC alpha:\", round(model_aic.alpha_, 4))\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(X_train, y_train)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "print(\"BIC alpha:\", round(model_bic.alpha_,4))\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot((alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline((alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'red')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3703ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lassoCV = LassoCV(max_iter=1000, cv=5)\n",
    "lassocv = LassoCV(alphas=None, cv=15, max_iter=100000, normalize=True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "print('The optimal alpha for the Lasso Regression is: ', lassocv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model(lassocv, X_train, X_test, y_train, y_test, 'Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f05299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 5th coeffcient of 'State' is shrinked to 0 - \n",
    "lasso_intercept = lassocv.intercept_\n",
    "lasso_coef = lassocv.coef_\n",
    "\n",
    "print(lasso_intercept, lasso_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bb13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coefficients\n",
    "plt.plot(range(len(lasso_coef)), lasso_coef)\n",
    "plt.xticks(range(len(lasso_coef)), features, rotation=60)\n",
    "plt.margins(0.02)\n",
    "plt.show();\n",
    "# the most important predictor for the target varaible is \"discount\"?\n",
    "# this is a type of feature selection very important for machine learning in a business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d4075a",
   "metadata": {},
   "source": [
    "### Ridge L2 norm regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losss function = standard OLS loss function + squared value of each coefficient mulitplied with some constant alpha/lambda - controls model complexity\n",
    "# when minimizing tthe losss function to fit to data, the model is penalized for large coeeficient of large magnitude\n",
    "# alphas = np.logspace(-4, 0, 50)\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "ridgecv = RidgeCV(alphas=alphas, normalize=True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "\n",
    "ridge = Ridge(alpha=ridgecv.alpha_, normalize=True)\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# large aplaph means the large coefficients are significantly penalized\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alphas, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alphas, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e235c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model(ridge, X_train, X_test, y_train, y_test, 'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eca84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = list()\n",
    "for a in alphas:\n",
    "    ridge_clf = RidgeCV(alphas=[a],cv=10).fit(X, y)\n",
    "    w.append(ridge_clf.coef_)\n",
    "\n",
    "w = np.array(w)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.semilogx(alphas,w)\n",
    "plt.title('Ridge coefficients as function of the regularization')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.legend(X.keys())\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afcd2c7",
   "metadata": {},
   "source": [
    "Both lasso and ridge regression show alpha is close to 0 which indicates regression is back to the standard OLS regression, no over-fitting is accounted for.\n",
    "Setting 'normalized = true' ensures that all variables are on the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e64715",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f007610",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['log_sales', 'Sales', 'Year','Segment', 'City', 'Region',  'Months'], axis=1)\n",
    "y = df['Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013711f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #rfr = RandomForestRegressor(n_estimators=50, min_samples_split=2, random_state=42)\n",
    " #rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=500, random_state=42, min_samples_split=2, min_samples_leaf=1, max_depth=10, bootstrap=True)\n",
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    from sklearn.metrics import r2_score\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_model(rfr, X_train, X_test, y_train, y_test, 'rfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d46ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_test)\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals, marker='.')\n",
    "plt.axhline(y=0, linestyle='--', color='red');\n",
    "plt.savefig('images/residuals.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa10247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_RMSE(test, test_pred):    \n",
    "    return np.sqrt(mean_squared_error(test, test_pred))\n",
    "\n",
    "print(check_RMSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57594204",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9def2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b12d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7811bba",
   "metadata": {},
   "source": [
    "## Summary and further analysis\n",
    "\n",
    "Since the data was collected from 2014-2018, this model might not fully reflect all the price changes recently in the market. Moreover, features that were used in developing this algorithm, might not be enough to sufficiently describe the sales. The sales range is mainly less than ~$80, which is a bit small in my opinion.\n",
    "\n",
    "And lastly, the market of densely populated urban areas is definitely different from that of the rural area. This means more data needs to be collected for different regions across all 49 states in US in order to efficiently predict the sales for any particular area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe37019",
   "metadata": {},
   "source": [
    "The final data sets include:\n",
    "\n",
    "X_train, X_test - train/test split predictors for label encoded sets\n",
    "y_train, y_test - target values for all sets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
